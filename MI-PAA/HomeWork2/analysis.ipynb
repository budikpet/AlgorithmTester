{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of output files\n",
    "## Prepare environment, functions etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add local src directory to the path. Then we are able to import our files.\n",
    "module_path = os.path.abspath(os.path.join('src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import matplotlib\n",
    "from helpers import get_analysis_files, getFiles, FilePair\n",
    "from myDataClasses import AnalysisFile\n",
    "\n",
    "path = 'analysisOutput/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important functions\n",
    "\n",
    "def remove_bag_results(table):\n",
    "    delim_index = list(table.iloc[0]).index(\"|\")\n",
    "    \n",
    "    return table.iloc[:, 0:delim_index]\n",
    "\n",
    "def get_cols_list(path: str):\n",
    "    cols = pandas.read_csv(path, index_col=None, delimiter=\" \", header=None)\n",
    "    cols = remove_bag_results(cols)\n",
    "    return list(cols.iloc[0])\n",
    "\n",
    "def load_analysis_files(folder_path: str, column_list):\n",
    "    files: AnalysisFile = get_analysis_files(folder_path)\n",
    "    output_table = None\n",
    "    \n",
    "    for file in files:\n",
    "        curr_table = pandas.read_csv(file.full_path, index_col=None, delimiter=\" \", header=None)\n",
    "        curr_table = remove_bag_results(curr_table)\n",
    "        curr_table.columns = column_list\n",
    "        curr_table[\"dataset\"] = file.dataset\n",
    "        curr_table[\"strategy\"] = file.strategy\n",
    "        \n",
    "        if output_table is not None:\n",
    "            output_table = output_table.append(curr_table, ignore_index=True)\n",
    "        else:\n",
    "            output_table = curr_table\n",
    "    \n",
    "    output_table = output_table.set_index(['strategy', 'dataset', 'id', \"item_count\"])\n",
    "    return output_table\n",
    "\n",
    "def construct_table_from(filePair: FilePair):\n",
    "    solution_table = pandas.read_csv(filePair.solutionFile, header=None, index_col=None, delimiter=\" \")\n",
    "    data_table = pandas.read_csv(filePair.dataFile, header=None, index_col=None, delimiter=\" \")\n",
    "    \n",
    "    item_count = data_table.iloc[0, 1]\n",
    "    \n",
    "    solution_table = solution_table.drop_duplicates(subset=[0], keep='first').reset_index()\n",
    "\n",
    "    data_table = data_table.iloc[:, 4:]\n",
    "    data_table = data_table[data_table.columns[::2]]\n",
    "\n",
    "    info_table = pandas.concat([solution_table.iloc[:, 3], data_table.max(axis=1)], axis=1)\n",
    "    info_table.columns = [\"best_value\", \"max_cost\"]\n",
    "    info_table[\"item_count\"] = item_count\n",
    "    return info_table\n",
    "\n",
    "def get_info_from_datafiles(path: str):\n",
    "    dataset = path.split(\"/\")[-1]\n",
    "    output_table = None\n",
    "    for filePair in getFiles(path):\n",
    "        curr_table = construct_table_from(filePair)\n",
    "        curr_table[\"dataset\"] = dataset\n",
    "        curr_table = curr_table.set_index([\"dataset\", \"item_count\"])\n",
    "        \n",
    "        if output_table is not None:\n",
    "            output_table = output_table.append(curr_table)\n",
    "        else:\n",
    "            output_table = curr_table\n",
    "    \n",
    "    return output_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put data from all analysis files into tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column lists\n",
    "\n",
    "dp_cols = get_cols_list(f'{path}/DP/column_description_DP.dat')\n",
    "dpweight_cols = get_cols_list(f'{path}/DPWeight/column_description_DPWeight.dat')\n",
    "greedy_cols = get_cols_list(f'{path}/Greedy/column_description_Greedy.dat')\n",
    "greedyone_cols = get_cols_list(f'{path}/GreedyOne/column_description_GreedyOne.dat')\n",
    "fptas_cols = get_cols_list(f'{path}/FPTAS/column_description_FPTAS.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tables of all strategies\n",
    "dp_table = load_analysis_files(f'{path}/DP', dp_cols)\n",
    "dpweight_table = load_analysis_files(f'{path}/DPWeight', dpweight_cols)\n",
    "greedy_table = load_analysis_files(f'{path}/Greedy', greedy_cols)\n",
    "greedyone_table = load_analysis_files(f'{path}/GreedyOne', greedyone_cols)\n",
    "fptas_table = load_analysis_files(f'{path}/FPTAS', fptas_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get average time values for all strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all table rows into 1 table\n",
    "avg_times = fptas_table.drop([\"relative_error\"], axis=1).append(dp_table).append(dpweight_table).append(greedy_table).append(greedyone_table)\n",
    "\n",
    "# Create a table of average times according to strategy and item_count columns\n",
    "avg_times = avg_times.groupby([\"strategy\", \"item_count\"])[\"time\"].mean().reset_index().set_index([\"strategy\", \"item_count\"])\n",
    "avg_times = avg_times.round(4)\n",
    "\n",
    "# Move all values of strategy column into separate columns\n",
    "avg_times = avg_times.unstack(\"strategy\")\n",
    "avg_times.columns = avg_times.columns.droplevel()\n",
    "\n",
    "# Save the dataframe to csv\n",
    "avg_times.to_csv ('analysisOutput/avg_times.csv', header=True)\n",
    "\n",
    "avg_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FPTAS error/item_count analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nk_info = get_info_from_datafiles(\"data/NK\")\n",
    "zkc_info = get_info_from_datafiles(\"data/ZKC\")\n",
    "zkw_info = get_info_from_datafiles(\"data/ZKW\")\n",
    "\n",
    "nk_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
