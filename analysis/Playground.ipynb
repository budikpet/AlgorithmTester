{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for renaming and moving solution files from tester_results to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = \"/Users/petr/Documents/Projects/Python/AlgorithmTester/analysis/tester_results/DataAnalysis\"\n",
    "dest_path = \"/Users/petr/Documents/Projects/Python/AlgorithmTester/data/DataAnalysis\"\n",
    "\n",
    "dry_run: bool = True\n",
    "\n",
    "for root, dirs, files in os.walk(source_path):\n",
    "    print(f\"{root}\")\n",
    "    dir_name: str = root.split(\"/\")[-1]\n",
    "    for filename in files:\n",
    "        if \"column\" in filename or \"DPWeight\" not in filename:\n",
    "            continue\n",
    "                   \n",
    "        split = filename.split(\"_\")\n",
    "        split = [split[0], split[1], split[4]]\n",
    "        new_name: str = '_'.join(split)\n",
    "            \n",
    "        print(f'{dest_path}/{dir_name}/{split[1]}/{new_name}')\n",
    "            \n",
    "        if not dry_run:\n",
    "            os.rename(f'{root}/{filename}', f'{dest_path}/{dir_name}/{split[1]}/{new_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read lines of file in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "filepath: str = '../data/UnitTest/NK10_inst.dat'\n",
    "\n",
    "# How many lines are read at once    \n",
    "batch_size: int = 50\n",
    "    \n",
    "with open(filepath, \"r\") as file:\n",
    "    batch: List[str] = [x.strip() for x in islice(file, batch_size)]\n",
    "    while len(batch) > 0:\n",
    "        for instance in batch:\n",
    "            print(instance)\n",
    "        \n",
    "        batch = [x.strip() for x in islice(file, batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from package_parsers.knapsack_parser import KnapsackParser\n",
    "\n",
    "def get_batch(parser, file, batch_size):\n",
    "    batch = list()\n",
    "    cntr: int = 0\n",
    "    parsed_data = parser.get_next_instance(file)\n",
    "    \n",
    "    while (parsed_data is not None) and cntr < batch_size:\n",
    "        batch.append(parsed_data)\n",
    "\n",
    "        cntr += 1\n",
    "        parsed_data = parser.get_next_instance(file)\n",
    "        \n",
    "    return batch\n",
    "\n",
    "parser: KnapsackParser = KnapsackParser()\n",
    "filepath: str = '../data/UnitTest/NK10_inst.dat'\n",
    "\n",
    "# How many lines are read at once    \n",
    "batch_size: int = 5\n",
    "    \n",
    "with open(filepath, \"r\") as file:\n",
    "    batch = get_batch(parser, file, batch_size)\n",
    "    \n",
    "    while len(batch) > 0:\n",
    "        print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yield test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance(cnt: int):\n",
    "    for i in range(cnt):\n",
    "        yield i\n",
    "    \n",
    "algorithms = [\"A\", \"B\", \"C\"]\n",
    "\n",
    "for alg in algorithms:\n",
    "    it = get_instance(5)\n",
    "    \n",
    "    for res in it:\n",
    "        print(f'{alg}:{res}')\n",
    "        \n",
    "    print(\"---------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy ConcurrencyStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "# Common functions\n",
    "\n",
    "def get_res(algorithm: str, instance: Dict[str, object]):\n",
    "    print(f\"Getting res for {instance} using {algorithm}.\")\n",
    "    time.sleep(1)\n",
    "    return f'Ran {algorithm} for {instance}.'\n",
    "\n",
    "def get_instance(file: str):\n",
    "    output = dict()\n",
    "    \n",
    "    for i in range(2):\n",
    "        output = {\"input\": file, \"instance\": i}\n",
    "        yield output\n",
    "    \n",
    "def run_tester_for_file(filename: str):\n",
    "    for algorithm in [\"A\", \"B\"]:\n",
    "        it = get_instance(f'{filename}_opened')\n",
    "        \n",
    "        for instance in it:\n",
    "            res = get_res(algorithm, instance)\n",
    "            print(f\"Writing (\\'{res}\\') to results file for input file {filename}.\")\n",
    "\n",
    "            \n",
    "# Runners\n",
    "filenames = [f'File{i}' for i in range(2)]\n",
    "\n",
    "\n",
    "class BaseRunner:\n",
    "    \n",
    "    def start(self):\n",
    "        for filename in filenames:\n",
    "            run_tester_for_file(filename)\n",
    "\n",
    "class ConcurrentFilesRunner:\n",
    "    \n",
    "    def start(self):\n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            batch = filenames\n",
    "            futures = [executor.submit(run_tester_for_file, filename) for filename in batch]\n",
    "            \n",
    "class ConcurrentInstancesRunner:\n",
    "    \n",
    "    def start(self):\n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            batch = filenames\n",
    "            \n",
    "            #concurrent.future.as_completed(futures)\n",
    "            for filename in filenames:\n",
    "                for algorithm in [\"A\", \"B\"]:\n",
    "                    batch = [instance for instance in get_instance(f'{filename}_opened')]\n",
    "                    futures = [executor.submit(get_res, instance, algorithm) for instance in batch]\n",
    "\n",
    "                    for future in concurrent.futures.as_completed(futures):\n",
    "                        res = future.result()\n",
    "                        print(f\"Writing (\\'{res}\\') to results file for input file {filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test BaseRunner\n",
    "start = time.perf_counter()\n",
    "\n",
    "simple_runner = BaseRunner()\n",
    "simple_runner.start()\n",
    "\n",
    "finish = time.perf_counter()\n",
    "print(f'Finished task in {round(finish - start, 2)} second(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ConcurrentFilesRunner\n",
    "start = time.perf_counter()\n",
    "\n",
    "simple_runner = ConcurrentFilesRunner()\n",
    "simple_runner.start()\n",
    "\n",
    "finish = time.perf_counter()\n",
    "print(f'Finished task in {round(finish - start, 2)} second(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ConcurrentInstancesRunner\n",
    "start = time.perf_counter()\n",
    "\n",
    "simple_runner = ConcurrentInstancesRunner()\n",
    "simple_runner.start()\n",
    "\n",
    "finish = time.perf_counter()\n",
    "print(f'Finished task in {round(finish - start, 2)} second(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
