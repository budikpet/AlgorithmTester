{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of output files\n",
    "## Prepare environment, functions etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas\n",
    "import matplotlib\n",
    "import numpy\n",
    "from algorithm_tester.helpers import FilePair\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Zapnout zobrazování grafů (procento uvozuje „magickou” zkratku IPythonu):\n",
    "%matplotlib inline\n",
    "\n",
    "path = 'tester_results'\n",
    "evo_path = f'{path}/evo_files'\n",
    "sol_path = '../data'\n",
    "\n",
    "sol_cols = [\"output_filename\", \"best_value\"]\n",
    "evo_cols = [\"output_filename\", \"num_of_satisfied_clauses\", \"weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas.set_option('display.max_rows', None)\n",
    "#pandas.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths_from_dir(path: str, include_sol: bool = False, include_instance: bool = True) -> (str, str, str):\n",
    "    dataset_prefix: str = path.split(\"/\")[-1]\n",
    "    for root, _, files in os.walk(path):\n",
    "        dataset: str = dataset_prefix + \"_\" + \"_\".join(root.replace(path, \"\")[1:].split('/'))\n",
    "        for file in files:\n",
    "            if \"column\" not in file and \".dat\" in file:\n",
    "                if (\"_sol\" in file and include_sol) or (\"_inst\" in file and include_instance):\n",
    "                    yield (dataset, root, file)\n",
    "\n",
    "def get_cols_list(path: str):\n",
    "    cols = pandas.read_csv(path, index_col=None, delimiter=\" \", header=None)\n",
    "    return list(cols.iloc[0])\n",
    "\n",
    "def create_avg_time_table(table, name: str, column_name: str = \"item_count\"):\n",
    "    # Create a table of average times according to algorithm and item_count columns\n",
    "    avg_times = table.groupby([\"algorithm_name\", column_name])['elapsed_time'] \\\n",
    "        .mean().reset_index()\n",
    "    avg_times = avg_times.round(2)\n",
    "    \n",
    "    avg_configs = table.groupby([\"algorithm_name\", column_name])['elapsed_configs']\\\n",
    "        .mean().reset_index()\n",
    "    \n",
    "    avg_times = avg_times.merge(avg_configs, on=[\"algorithm_name\", column_name])\n",
    "\n",
    "    # Move all values of algorithm column into separate columns\n",
    "    #avg_times = avg_times.unstack(\"algorithm_name\")\n",
    "    #avg_times.columns = avg_times.columns.droplevel()\n",
    "    avg_times.name = f\"Avg #configs per {column_name}\"\n",
    "    avg_times.sort_values(by=column_name, inplace=True)\n",
    "    #avg_times.fillna(\"-\", inplace=True)\n",
    "\n",
    "    # Save the dataframe to csv\n",
    "    #avg_times.to_excel(f'excel/{name}_avg_times.xlsx', sheet_name=name)\n",
    "    \n",
    "    return avg_times\n",
    "\n",
    "def create_avg_error_table(table, column_name: str, table_name: str = \"unknown\"):\n",
    "    table[\"relative_error\"] = numpy.abs(table[\"best_value\"] - table[\"found_value\"])/table[\"best_value\"]\n",
    "    table = table.fillna(0)\n",
    "    \n",
    "    error_group = table.groupby([column_name, \"algorithm_name\"])[\"relative_error\"]\n",
    "\n",
    "    error_max = error_group.max().reset_index() \\\n",
    "        .rename(columns={'relative_error':'max_relative_error'})\n",
    "    error_avg = error_group.mean().reset_index() \\\n",
    "        .rename(columns={'relative_error':'avg_relative_error'})\n",
    "    \n",
    "    # Construct, unstack\n",
    "    avg_error = pandas.merge(error_max, error_avg, on=[column_name, \"algorithm_name\"])\n",
    "    #avg_error = avg_error.set_index([\"algorithm_name\", column_name]).unstack(\"algorithm_name\")\n",
    "    #avg_error = error_max.join(error_avg).round(6)\n",
    "    #avg_error.columns = [\"max_relative_error\", \"avg_relative_error\"]\n",
    "    avg_error.name = f\"Avg & max relative error per {column_name}\"\n",
    "    \n",
    "    \n",
    "    avg_error.set_index([\"algorithm_name\", column_name]).unstack(\"algorithm_name\")\\\n",
    "        .round(6)\\\n",
    "        .to_excel(f\"excel/{table_name}_avg_error.xlsx\", sheet_name=table_name)\n",
    "    \n",
    "    return avg_error\n",
    "\n",
    "def save_plot(table, title: str, column_name: str, output_name: str, y_label: str = \"Relative errors\"):\n",
    "    worktable = table.loc[:, column_name].copy()\n",
    "    \n",
    "    plot = worktable.plot()\n",
    "    plot.set_ylabel(y_label)\n",
    "\n",
    "    figure = plot.get_figure()\n",
    "    figure.suptitle(title)\n",
    "    figure.savefig(f\"excel/{output_name}.pdf\")\n",
    "    \n",
    "    return plot\n",
    "\n",
    "def save_table(table, output_name):\n",
    "    table.round(6).to_excel(f\"excel/{output_name}_table.xlsx\", sheet_name=output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_evo_plot(title: str, ylabel: str = \"Satisfied clauses\"):\n",
    "    fig, axes = plt.subplots(1, 1, sharex=True, sharey=True, figsize=[13,3])\n",
    "    axes.set_xlabel('step')\n",
    "    axes.set_ylabel(ylabel)\n",
    "    axes.set_title(title)\n",
    "    \n",
    "    return fig, axes\n",
    "\n",
    "def get_evo_table(path: str, column: str = \"num_of_satisfied_clauses\"):\n",
    "    evo_table = pandas.read_csv(path, index_col=None, delimiter=\" \", header=None)\n",
    "    evo_table.columns = evo_cols\n",
    "    evo_table[\"step\"] = range(evo_table[column].count())\n",
    "    return evo_table\n",
    "    \n",
    "def add_evo_plot(path: str, yaxis_label: str, axes, column: str = \"num_of_satisfied_clauses\"):\n",
    "    evo_table = get_evo_table(path)\n",
    "    \n",
    "    data = evo_table.sort_values(by=\"step\").set_index([\"step\"]).loc[:, column]\n",
    "    \n",
    "    ax = axes.plot(data, label=yaxis_label)\n",
    "    return evo_table\n",
    "\n",
    "def get_full_table_for_dataset(instance_path: str, sol_path: str, instance_cols, sol_cols):\n",
    "    output_table = None\n",
    "    \n",
    "    # Get all solutions from all files\n",
    "    output_table = pandas.read_csv(instance_path, index_col=None, delimiter=\" \", header=None)\\\n",
    "        .iloc[:, [0, 1,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1]]\n",
    "    output_table.columns = instance_cols\n",
    "\n",
    "    # Add data from solution file\n",
    "    sols_table = pandas.read_csv(sol_path, index_col=None, delimiter=\" \", header=None)\\\n",
    "        .iloc[:, [0, 1]]\n",
    "    sols_table.columns = sol_cols\n",
    "    sols_table.drop_duplicates(subset=\"output_filename\", inplace=True)\n",
    "        \n",
    "    output_table = pandas.merge(sols_table, output_table, on=[\"output_filename\"], how=\"outer\")\n",
    "    output_table = output_table.astype({'found_value': 'int64'})\n",
    "    output_table[\"relative_mistake_weights\"] = numpy.abs(output_table[\"best_value\"] - output_table[\"found_value\"])/output_table[\"best_value\"]\n",
    "\n",
    "    output_table[\"relative_mistake_clauses\"] = (output_table[\"num_of_clauses\"] - output_table[\"num_of_satisfied_clauses\"])/output_table[\"num_of_satisfied_clauses\"]\n",
    "    output_table[\"has_best_value\"] = ~numpy.isnan(output_table[\"best_value\"])\n",
    "    \n",
    "    output_table = output_table.fillna(0.0).astype({'best_value': 'int64'})\n",
    "    \n",
    "    return output_table\n",
    "\n",
    "def get_all_tables_of_results(base: str):\n",
    "    cols = get_cols_list(\"column_description.dat\")\n",
    "    cols.remove(\"vars_output\")\n",
    "    dfs = list()\n",
    "    \n",
    "    datasets = [\n",
    "        \"wuf-A/wuf20-88-A\",\n",
    "        \"wuf-A/wuf20-91-A\",\n",
    "        \n",
    "        \"wuf-M/wuf20-78-M\",\n",
    "        \"wuf-M/wuf50-201-M\",\n",
    "        \n",
    "        \"wuf-N/wuf20-78-N\",\n",
    "        \"wuf-N/wuf50-201-N\",\n",
    "        \n",
    "        \"wuf-Q/wuf20-78-Q\",\n",
    "        \"wuf-Q/wuf50-201-Q\",\n",
    "        \n",
    "        \"wuf-R/wuf20-78-R\",\n",
    "        \"wuf-R/wuf50-201-R\"\n",
    "    ]\n",
    "    for algorithm in [\"SA_SAT_V1\", \"SA_SAT_V2\", \"SA_SAT_V3\"]:\n",
    "        \n",
    "        for dataset in datasets:\n",
    "            d = get_full_table_for_dataset(f'{base}/{dataset}_{algorithm}.dat', f'{sol_path}/{dataset}-opt.dat', cols, sol_cols)\n",
    "            dfs.append(d)\n",
    "    \n",
    "    return pandas.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_simple = get_all_tables_of_results(\"tester_results_V1_Simple\")\n",
    "v2_moreCooling = get_all_tables_of_results(\"tester_results_V2_MoreCooling\")\n",
    "v3_higherTemp = get_all_tables_of_results(\"tester_results_V3_HigherTemp\")\n",
    "\n",
    "v1_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_avg_error_table_by_best_value(table, column_name: str, table_name: str = \"unknown\"):\n",
    "    t = table.query(\"has_best_value == True\").copy()\n",
    "    t = t.fillna(0)\n",
    "    \n",
    "    error_group = table.groupby([column_name, \"algorithm_name\"])[\"relative_mistake_weights\"]\n",
    "\n",
    "    error_max = error_group.max().reset_index() \\\n",
    "        .rename(columns={'relative_mistake_weights':'max_relative_error'})\n",
    "    error_avg = error_group.mean().reset_index() \\\n",
    "        .rename(columns={'relative_mistake_weights':'avg_relative_error'})\n",
    "    \n",
    "    # Construct, unstack\n",
    "    avg_error = pandas.merge(error_max, error_avg, on=[column_name, \"algorithm_name\"])\n",
    "    #avg_error = avg_error.set_index([\"algorithm_name\", column_name]).unstack(\"algorithm_name\")\n",
    "    #avg_error = error_max.join(error_avg).round(6)\n",
    "    #avg_error.columns = [\"max_relative_error\", \"avg_relative_error\"]\n",
    "    avg_error.name = f\"Avg & max relative error per {column_name}\"\n",
    "    avg_error = avg_error.set_index([\"algorithm_name\", column_name]).unstack(\"algorithm_name\")\n",
    "    \n",
    "    \n",
    "    #avg_error.round(6).to_excel(f\"excel/{table_name}_avg_error.xlsx\", sheet_name=table_name)\n",
    "    \n",
    "    return avg_error\n",
    "\n",
    "create_avg_error_table_by_best_value(v1_simple, \"num_of_clauses\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = init_evo_plot(\"Evolution of costs for different init temperatures\")\n",
    "\n",
    "add_evo_plot(f\"{evo_path}/wuf50-0987_SA_SAT_V3_sol.evo\", evo_cols, \"1500\", axes)\n",
    "#add_evo_plot(f\"{evo_path}/wuf50-0987_SA_SAT_V3_sol.evo\", evo_cols, \"2500\", axes)\n",
    "axes.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table = nk_table.append(zkc_table).append(zkw_table).query(\"algorithm_name != 'SA_OLD'\")\n",
    "sapenalty_error_comp = create_avg_error_table(full_table, \"item_count\", \"sapenalty_comp\")\\\n",
    "    .set_index([\"item_count\", \"algorithm_name\"]).unstack(\"algorithm_name\")\\\n",
    "    .drop(columns=\"max_relative_error\")\n",
    "\n",
    "sapenalty_comp_plot = sapenalty_error_comp.plot.bar(legend=True)\n",
    "sapenalty_comp_plot.set_ylabel(\"Relative errors\")\n",
    "\n",
    "figure = sapenalty_comp_plot.get_figure()\n",
    "figure.suptitle(\"SA/SAPenalty relative error comparison\")\n",
    "figure.savefig(\"excel/sapenalty_comp.pdf\")\n",
    "\n",
    "sapenalty_comp_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(error_init_temp)\n",
    "\n",
    "out = pandas.merge(error_init_temp, time_init_temp, on=[\"algorithm_name\", \"init_temp\"])\n",
    "save_table(out, \"init_temp_errors_speed\")\n",
    "save_plot(error_init_temp, \"Avg error - init temperatures\", \"avg_relative_error\", \"init_temp_avg_error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time_init_temp)\n",
    "\n",
    "save_plot(time_init_temp, \"Avg speed - init temperatures\", \"elapsed_time\", \"init_temp_time_ms\", \"Time[ms]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plot(time_init_temp, \"Avg speed - init temperatures\", \"elapsed_configs\", \"init_temp_time_configs\", \"Time[configs]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = init_evo_plot(\"Evolution of costs for different init temperatures\")\n",
    "\n",
    "add_evo_plot(f\"{evo_path}/InitTemperature/EvoFile_40_inst_SA_1500.evo\", evo_cols, \"1500\", axes)\n",
    "add_evo_plot(f\"{evo_path}/InitTemperature/EvoFile_40_inst_SA_2500.evo\", evo_cols, \"2500\", axes)\n",
    "axes.legend()\n",
    "\n",
    "fig.savefig(f\"excel/init_temp_evo.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
