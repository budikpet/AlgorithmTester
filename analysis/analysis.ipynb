{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of output files\n",
    "## Prepare environment, functions etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add local src directory to the path. Then we are able to import our files.\n",
    "# module_path = os.path.abspath(os.path.join('algorithm_tester'))\n",
    "# if module_path not in sys.path:\n",
    "#    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "# import matplotlib\n",
    "import numpy\n",
    "from algorithm_tester.helpers import get_analysis_files, getFiles, FilePair\n",
    "from algorithm_tester.mydataclasses import AnalysisFile\n",
    "\n",
    "# Zapnout zobrazování grafů (procento uvozuje „magickou” zkratku IPythonu):\n",
    "# %matplotlib inline\n",
    "\n",
    "path = 'tester_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas.set_option('display.max_rows', None)\n",
    "#pandas.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important functions\n",
    "\n",
    "def remove_bag_results(table):\n",
    "    delim_index = list(table.iloc[0]).index(\"|\")\n",
    "    \n",
    "    return table.iloc[:, 0:delim_index]\n",
    "\n",
    "def get_cols_list(path: str):\n",
    "    cols = pandas.read_csv(path, index_col=None, delimiter=\" \", header=None)\n",
    "    cols = remove_bag_results(cols)\n",
    "    return list(cols.iloc[0])\n",
    "\n",
    "def load_analysis_files(folder_path: str, column_list):\n",
    "    files: AnalysisFile = get_analysis_files(folder_path)\n",
    "    output_table = None\n",
    "    \n",
    "    for file in files:\n",
    "        curr_table = pandas.read_csv(file.full_path, index_col=None, delimiter=\" \", header=None)\n",
    "        curr_table = remove_bag_results(curr_table)\n",
    "        curr_table.columns = column_list\n",
    "        curr_table[\"instance_info\"] = file.instance_info\n",
    "        curr_table[\"dataset\"] = file.dataset\n",
    "        \n",
    "        # curr_table[\"strategy\"] = file.strategy\n",
    "        \n",
    "        if output_table is not None:\n",
    "            output_table = output_table.append(curr_table, ignore_index=True)\n",
    "        else:\n",
    "            output_table = curr_table\n",
    "    \n",
    "    output_table = output_table.set_index(['strategy', 'dataset', 'id', \"item_count\"])\n",
    "    output_table.sort_values(by=[\"strategy\", \"dataset\", \"item_count\", \"id\"], inplace=True)\n",
    "    return output_table\n",
    "\n",
    "def construct_table_from(filePair: FilePair):\n",
    "    solution_table = pandas.read_csv(filePair.solutionFile, header=None, index_col=None, delimiter=\" \")\n",
    "    data_table = pandas.read_csv(filePair.dataFile, header=None, index_col=None, delimiter=\" \")\n",
    "    \n",
    "    item_count = data_table.iloc[0, 1]\n",
    "    \n",
    "    solution_table = solution_table.drop_duplicates(subset=[0], keep='first').reset_index()\n",
    "\n",
    "    data_table = data_table.iloc[:, 4:]\n",
    "    data_table = data_table[data_table.columns[::2]]\n",
    "\n",
    "    info_table = pandas.concat([solution_table.iloc[:, 1], solution_table.iloc[:, 3], data_table.max(axis=1)], axis=1)\n",
    "    info_table.columns = [\"id\", \"best_value\", \"max_cost\"]\n",
    "    info_table[\"item_count\"] = item_count\n",
    "    return info_table\n",
    "\n",
    "def get_info_from_datafiles(path: str):\n",
    "    dataset = path.split(\"/\")[-1]\n",
    "    output_table = None\n",
    "    for filePair in getFiles(path):\n",
    "        curr_table = construct_table_from(filePair)\n",
    "        curr_table[\"dataset\"] = dataset\n",
    "        curr_table = curr_table.set_index([\"dataset\", \"item_count\", \"id\"])\n",
    "        \n",
    "        if output_table is not None:\n",
    "            output_table = output_table.append(curr_table)\n",
    "        else:\n",
    "            output_table = curr_table\n",
    "    \n",
    "    return output_table\n",
    "\n",
    "def create_avg_time(table, name: str, column: str = \"item_count\"):\n",
    "    # Create a table of average times according to strategy and item_count columns\n",
    "    avg_times = table.groupby([\"strategy\", column])['time[#configs]'] \\\n",
    "        .mean().reset_index().set_index([\"strategy\", column])\n",
    "    avg_times = avg_times.round(2)\n",
    "\n",
    "    # Move all values of strategy column into separate columns\n",
    "    avg_times = avg_times.unstack(\"strategy\")\n",
    "    avg_times.columns = avg_times.columns.droplevel()\n",
    "    #avg_times.fillna(\"-\", inplace=True)\n",
    "\n",
    "    # Save the dataframe to csv\n",
    "    avg_times.to_excel(f'excel/avg_times_{name}.xlsx', header=True)\n",
    "    \n",
    "    return avg_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put data from all analysis files into tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column lists\n",
    "\n",
    "cols = get_cols_list(f'{path}/column_description.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-34898d5ca6f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mthings_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_analysis_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{path}/Things'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"instance_info\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mweight_cap_ratio_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_analysis_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{path}/WeightCapRation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'instance_info'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'ratio'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-92d99a9277c9>\u001b[0m in \u001b[0;36mload_analysis_files\u001b[0;34m(folder_path, column_list)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mcurr_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mcurr_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_bag_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mcurr_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/Python/AlgorithmTester/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/Python/AlgorithmTester/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/Python/AlgorithmTester/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/Python/AlgorithmTester/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/Python/AlgorithmTester/venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "# Load tables of all strategies\n",
    "# balance_table = load_analysis_files(f'{path}/Balance', cols)\n",
    "# correlation_table = load_analysis_files(f'{path}/Correlation', cols)\n",
    "# granularity_heavy_table = load_analysis_files(f'{path}/GranularityHeavy', cols)\n",
    "# granularity_light_table = load_analysis_files(f'{path}/GranularityLight', cols)\n",
    "maxcost_table = load_analysis_files(f'{path}/MaxCost', cols) \\\n",
    "    .rename(columns={'instance_info':'maxcost'})\n",
    "maxweight_table = load_analysis_files(f'{path}/MaxWeight', cols) \\\n",
    "    .rename(columns={'instance_info':'maxweight'})\n",
    "robust_table = load_analysis_files(f'{path}/Robust', cols) \\\n",
    "    .drop(columns=\"instance_info\")\n",
    "things_table = load_analysis_files(f'{path}/Things', cols) \\\n",
    "    .drop(columns=\"instance_info\")\n",
    "weight_cap_ratio_table = load_analysis_files(f'{path}/WeightCapRation', cols) \\\n",
    "    .rename(columns={'instance_info':'ratio'})\n",
    "\n",
    "weight_cap_ratio_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table of average times according to strategy and item_count columns\n",
    "create_avg_time(things_table, \"things\")\n",
    "\n",
    "# Create a greedy_table with computed relative_mistake\n",
    "greedy_table = things_table.iloc[things_table.index.get_level_values('strategy') == \"Greedy\"] \\\n",
    "    .rename(columns={'maximum_sum':'found_sum'}) \\\n",
    "    .drop(columns=\"time[#configs]\")\n",
    "dp_table = things_table.iloc[things_table.index.get_level_values('strategy') == \"DP\"] \\\n",
    "    .drop(columns=\"time[#configs]\")\n",
    "\n",
    "greedy_table = pandas.merge(greedy_table, dp_table, on=['id', 'item_count', 'dataset'], right_index=True) \\\n",
    "    .iloc[:, [1, 0]]\n",
    "greedy_table[\"relative_error\"] = numpy.abs(greedy_table[\"maximum_sum\"] - greedy_table[\"found_sum\"])/greedy_table[\"maximum_sum\"]\n",
    "\n",
    "# Create a table with max and average relative_mistake.\n",
    "error_group = greedy_table.groupby([\"strategy\", \"item_count\"])[\"relative_error\"]\n",
    "\n",
    "error_max = error_group.max().reset_index().set_index([\"strategy\", \"item_count\"]).rename(columns={'relative_error':'max_relative_error'})\n",
    "error_avg = error_group.mean().reset_index().set_index([\"strategy\", \"item_count\"]).rename(columns={'relative_error':'avg_relative_error'})\n",
    "\n",
    "# Construct, unstack\n",
    "avg_mistake = error_max.join(error_avg).round(6).unstack(\"strategy\")\n",
    "avg_mistake.columns = [\"max_relative_error\", \"avg_relative_error\"]\n",
    "\n",
    "avg_mistake.to_excel(\"excel/avg_mistake_things.xlsx\")\n",
    "\n",
    "avg_mistake\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_analysis = robust_table.reset_index().drop_duplicates(subset=[\"strategy\", \"time[#configs]\"])\n",
    "robust_analysis.query(\"strategy == 'BB'\").to_excel(\"excel/not_robust.xlsx\")\n",
    "robust_analysis.query(\"strategy != 'BB'\").to_excel(\"excel/is_robust.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxCost analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table of average times according to strategy and item_count columns\n",
    "create_avg_time(maxcost_table, \"maxcost\", column = \"maxcost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxWeight analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table of average times according to strategy and item_count columns\n",
    "create_avg_time(maxweight_table, \"maxweight\", column = \"maxweight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WeightCapRatio analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table of average times according to strategy and item_count columns\n",
    "create_avg_time(weight_cap_ratio_table, \"weight_cap_ratio\", column = \"ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
