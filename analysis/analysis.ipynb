{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of output files\n",
    "## Prepare environment, functions etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas\n",
    "# import matplotlib\n",
    "import numpy\n",
    "from algorithm_tester.helpers import FilePair\n",
    "\n",
    "# Zapnout zobrazování grafů (procento uvozuje „magickou” zkratku IPythonu):\n",
    "# %matplotlib inline\n",
    "\n",
    "path = 'tester_results'\n",
    "solutions = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas.set_option('display.max_rows', None)\n",
    "#pandas.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths_from_dir(path: str, include_sol: bool = False, include_instance: bool = True) -> (str, str):\n",
    "    dataset_prefix: str = path.split(\"/\")[-1]\n",
    "    for root, _, files in os.walk(path):\n",
    "        dataset: str = dataset_prefix + \"_\" + \"_\".join(root.replace(path, \"\")[1:].split('/'))\n",
    "        for file in files:\n",
    "            if \"column\" not in file:\n",
    "                if (\"_sol\" in file and include_sol) or (\"_inst\" in file and include_instance):\n",
    "                    yield (dataset, f'{root}/{file}')\n",
    "\n",
    "def get_cols_list(path: str):\n",
    "    cols = pandas.read_csv(path, index_col=None, delimiter=\" \", header=None)\n",
    "    return list(cols.iloc[0])\n",
    "\n",
    "def load_sol_from_dir(folder_path: str, column_list):\n",
    "    \"\"\" Load solutions from directory files into table. \"\"\"\n",
    "    it = get_file_paths_from_dir(folder_path, include_sol=True, include_instance=False)\n",
    "    output_table = None\n",
    "        \n",
    "    for (dataset, filepath) in it:\n",
    "        curr_table = pandas.read_csv(filepath, index_col=None, delimiter=\" \", header=None).iloc[:,0:3]\n",
    "        curr_table.columns = column_list\n",
    "        curr_table[\"dataset\"] = dataset\n",
    "                \n",
    "        if output_table is not None:\n",
    "            output_table = output_table.append(curr_table, ignore_index=True)\n",
    "        else:\n",
    "            output_table = curr_table\n",
    "    \n",
    "    return output_table\n",
    "\n",
    "def load_data_from_dir(folder_path: str, column_list):\n",
    "    \"\"\" Load data from directory files into table. \"\"\"\n",
    "    it = get_file_paths_from_dir(folder_path)\n",
    "    output_table = None\n",
    "    \n",
    "    for (dataset, filepath) in it:\n",
    "        curr_table = pandas.read_csv(filepath, index_col=None, delimiter=\" \", header=None)\n",
    "        curr_table.columns = column_list\n",
    "        curr_table[\"dataset\"] = dataset\n",
    "                \n",
    "        if output_table is not None:\n",
    "            output_table = output_table.append(curr_table, ignore_index=True)\n",
    "        else:\n",
    "            output_table = curr_table\n",
    "    \n",
    "    #output_table = output_table.set_index(['algorithm', 'dataset', 'id', \"item_count\"])\n",
    "    #output_table.sort_values(by=[\"algorithm\", \"dataset\", \"item_count\", \"id\"], inplace=True)\n",
    "    return output_table\n",
    "\n",
    "def construct_table_from(filePair: FilePair):\n",
    "    solution_table = pandas.read_csv(filePair.solutionFile, header=None, index_col=None, delimiter=\" \")\n",
    "    data_table = pandas.read_csv(filePair.dataFile, header=None, index_col=None, delimiter=\" \")\n",
    "    \n",
    "    item_count = data_table.iloc[0, 1]\n",
    "    \n",
    "    solution_table = solution_table.drop_duplicates(subset=[0], keep='first').reset_index()\n",
    "\n",
    "    data_table = data_table.iloc[:, 4:]\n",
    "    data_table = data_table[data_table.columns[::2]]\n",
    "\n",
    "    info_table = pandas.concat([solution_table.iloc[:, 1], solution_table.iloc[:, 3], data_table.max(axis=1)], axis=1)\n",
    "    info_table.columns = [\"id\", \"best_value\", \"max_cost\"]\n",
    "    info_table[\"item_count\"] = item_count\n",
    "    return info_table\n",
    "\n",
    "def create_avg_time(table, name: str, column: str = \"item_count\"):\n",
    "    # Create a table of average times according to algorithm and item_count columns\n",
    "    avg_times = table.groupby([\"algorithm\", column])['time[#configs]'] \\\n",
    "        .mean().reset_index().set_index([\"algorithm\", column])\n",
    "    avg_times = avg_times.round(2)\n",
    "\n",
    "    # Move all values of algorithm column into separate columns\n",
    "    avg_times = avg_times.unstack(\"algorithm\")\n",
    "    avg_times.columns = avg_times.columns.droplevel()\n",
    "    avg_times.name = f\"Avg #configs per {column}\"\n",
    "    #avg_times.fillna(\"-\", inplace=True)\n",
    "\n",
    "    # Save the dataframe to csv\n",
    "    avg_times.to_excel(f'excel/{name}_avg_times.xlsx', sheet_name=name)\n",
    "    \n",
    "    return avg_times\n",
    "\n",
    "def create_avg_error(table, name: str, column: str, exact_strategy_name: str = \"DP\"):\n",
    "    greedy_table = table.iloc[table.index.get_level_values('algorithm') == \"Greedy\"] \\\n",
    "        .rename(columns={'maximum_sum':'found_sum'})\n",
    "    exact_table = table.iloc[table.index.get_level_values('algorithm') == exact_strategy_name] \\\n",
    "        .drop(columns=\"time[#configs]\")\n",
    "    \n",
    "    if column not in greedy_table.index.names:\n",
    "        greedy_table = greedy_table.loc[:, [\"found_sum\", column]]\n",
    "        greedy_table = pandas.merge(greedy_table, exact_table, how=\"left\", on=['id', 'item_count', column])\n",
    "    else:\n",
    "        greedy_table = greedy_table.loc[:, [\"found_sum\"]]\n",
    "        greedy_table = pandas.merge(greedy_table, exact_table, how=\"left\", on=['id', 'item_count'])\n",
    "        \n",
    "    greedy_table[\"relative_error\"] = numpy.abs(greedy_table[\"maximum_sum\"] - greedy_table[\"found_sum\"])/greedy_table[\"maximum_sum\"]\n",
    "        \n",
    "    # Create a table with max and average relative_error.\n",
    "    error_group = greedy_table.groupby([column])[\"relative_error\"]\n",
    "\n",
    "    error_max = error_group.max().reset_index().set_index([column]) \\\n",
    "        .rename(columns={'relative_error':'max_relative_error'})\n",
    "    error_avg = error_group.mean().reset_index().set_index([column]) \\\n",
    "        .rename(columns={'relative_error':'avg_relative_error'})\n",
    "\n",
    "    # Construct, unstack\n",
    "    avg_error = error_max.join(error_avg).round(6)\n",
    "    avg_error.columns = [\"max_relative_error\", \"avg_relative_error\"]\n",
    "    avg_error.name = f\"Avg & max relative error per {column}\"\n",
    "\n",
    "    avg_error.to_excel(f\"excel/{name}_avg_error.xlsx\", sheet_name=name)\n",
    "\n",
    "    return avg_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column lists\n",
    "\n",
    "sol_cols = [\"id\", \"item_count\", \"best_value\"]\n",
    "cols = get_cols_list(f'{path}/column_description.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put data from all analysis files into tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tables of all strategies\n",
    "#balance_table = load_data_from_dir(f'{path}/Balance', cols) \\\n",
    "#    .rename(columns={'instance_info':'balance'})\n",
    "#robust_table = load_data_from_dir(f'{path}/Robust', cols) \\\n",
    "#    .drop(columns=\"instance_info\")\n",
    "\n",
    "nk_table = load_data_from_dir(f'{path}/NK', cols) \\\n",
    "    .drop(columns=\"things\") \\\n",
    "    .merge(load_sol_from_dir(f'{solutions}/NK', sol_cols).drop(columns=\"dataset\"), on=[\"id\", \"item_count\"])\n",
    "zkc_table = load_data_from_dir(f'{path}/ZKC', cols) \\\n",
    "    .drop(columns=\"things\") \\\n",
    "    .merge(load_sol_from_dir(f'{solutions}/ZKC', sol_cols).drop(columns=\"dataset\"), on=[\"id\", \"item_count\"])\n",
    "zkw_table = load_data_from_dir(f'{path}/ZKW', cols) \\\n",
    "    .drop(columns=\"things\") \\\n",
    "    .merge(load_sol_from_dir(f'{solutions}/ZKW', sol_cols).drop(columns=\"dataset\"), on=[\"id\", \"item_count\"])\n",
    "nk_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = zkw_table\n",
    "table[\"relative_error\"] = numpy.abs(table[\"best_value\"] - table[\"found_value\"])/table[\"best_value\"]\n",
    "table.query(\"relative_error > 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_sols = load_sol_from_dir(f'{solutions}/ParamAnalysis', sol_cols) \\\n",
    "    .drop(columns=\"dataset\")\n",
    "\n",
    "init_temperature_table = load_data_from_dir(f'{path}/ParamAnalysis/InitTemperature', cols) \\\n",
    "    .drop(columns=[\"things\", \"cycles\", \"min_temperature\", \"cooling\"]) \\\n",
    "    .merge(param_sols, on=[\"id\", \"item_count\"])\n",
    "\n",
    "cooling_table = load_data_from_dir(f'{path}/ParamAnalysis/Cooling', cols) \\\n",
    "    .drop(columns=[\"things\", \"cycles\", \"min_temperature\", \"init_temperature\"]) \\\n",
    "    .merge(param_sols, on=[\"id\", \"item_count\"])\n",
    "\n",
    "cycles_table = load_data_from_dir(f'{path}/ParamAnalysis/Cycles', cols) \\\n",
    "    .drop(columns=[\"things\", \"init_temperature\", \"min_temperature\", \"cooling\"]) \\\n",
    "    .merge(param_sols, on=[\"id\", \"item_count\"])\n",
    "\n",
    "init_temperature_table[\"dataset\"] = init_temperature_table[\"dataset\"].str.split(\"_\", n = 1, expand = True)[1]\n",
    "cooling_table[\"dataset\"] = cooling_table[\"dataset\"].str.split(\"_\", n = 1, expand = True)[1]\n",
    "cycles_table[\"cycles\"] = cycles_table[\"dataset\"].str.split(\"_\", n = 1, expand = True)[1]\n",
    "\n",
    "cooling_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def f(table):\n",
    "    table[\"relative_error\"] = numpy.abs(table[\"best_value\"] - table[\"found_value\"])/table[\"best_value\"]\n",
    "    table = table.fillna(0) \\\n",
    "        .replace([numpy.inf, -numpy.inf], numpy.nan).dropna()\n",
    "    \n",
    "    error_group = table.groupby([\"dataset\", \"algorithm_name\"])[\"relative_error\"]\n",
    "\n",
    "    error_max = error_group.max().reset_index() \\\n",
    "        .rename(columns={'relative_error':'max_relative_error'})\n",
    "    error_avg = error_group.mean().reset_index() \\\n",
    "        .rename(columns={'relative_error':'avg_relative_error'})\n",
    "    \n",
    "    # Construct, unstack\n",
    "    avg_error = pandas.merge(error_max, error_avg, on=[\"dataset\", \"algorithm_name\"])\n",
    "    #avg_error = error_max.join(error_avg).round(6)\n",
    "    #avg_error.columns = [\"max_relative_error\", \"avg_relative_error\"]\n",
    "    avg_error.name = f\"Avg & max relative error per \"\n",
    "\n",
    "    #avg_error.to_excel(f\"excel/{name}_avg_error.xlsx\", sheet_name=name)\n",
    "    \n",
    "    return avg_error\n",
    "\n",
    "error_init_temperature = f(init_temperature_table)\n",
    "error_cooling = f(cooling_table)\n",
    "error_cycles = f(cycles_table)\n",
    "error_init_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_table = pandas.read_csv(f'{path}/TestSpeed/original.dat', index_col=None, delimiter=\" \", header=None)\n",
    "original_table.columns = cols\n",
    "\n",
    "original_table = original_table.iloc[:, [0, 1, 7, 9]]\n",
    "\n",
    "group = original_table.groupby([\"item_count\"])[\"elapsed_time\"]\n",
    "gmax = group.max().reset_index().rename(columns={'elapsed_time':'max_elapsed_time[ms]'})\n",
    "gavg = group.mean().reset_index().rename(columns={'elapsed_time':'avg_elapsed_time[ms]'})\n",
    "\n",
    "speed = pandas.merge(gmax, gavg, on=[\"item_count\"])\n",
    "speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_table2 = pandas.read_csv(f'{path}/TestSpeed/NK_40_inst_SA_sol.dat', index_col=None, delimiter=\" \", header=None)\n",
    "speed_table2.columns = cols\n",
    "\n",
    "speed_table2 = speed_table2.iloc[:, [0, 1, 7, 9]]\n",
    "\n",
    "group2 = speed_table2.groupby([\"item_count\"])[\"elapsed_time\"]\n",
    "gmax2 = group2.max().reset_index().rename(columns={'elapsed_time':'max_elapsed_time[ms]'})\n",
    "gavg2 = group2.mean().reset_index().rename(columns={'elapsed_time':'avg_elapsed_time[ms]'})\n",
    "\n",
    "speed2 = pandas.merge(gmax2, gavg2, on=[\"item_count\"])\n",
    "speed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
